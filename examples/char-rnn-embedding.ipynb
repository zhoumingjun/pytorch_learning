{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the pytorch version of karpathy's charnn\n",
    "    reference: https://gist.github.com/raphaelbastide/11ae4bb5e454e5c5239f\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has 1570 characters, 49 unique.\n"
     ]
    }
   ],
   "source": [
    "# data I/O\n",
    "data = open('input.txt', 'r').read() # should be simple plain text file\n",
    "chars = list(set(data))\n",
    "data_size, vocab_size = len(data), len(chars)\n",
    "print ('data has {} characters, {} unique.'.format( data_size, vocab_size))\n",
    "char_to_ix = { ch:i for i,ch in enumerate(chars) }\n",
    "ix_to_char = { i:ch for i,ch in enumerate(chars) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "token_size = vocab_size\n",
    "input_size = 4\n",
    "hidden_size = 100 # size of hidden layer of neurons\n",
    "seq_length = 25 # number of steps to unroll the RNN for\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "def ix_to_tensor(ix):\n",
    "    return Variable(torch.LongTensor([[ix]]))\n",
    "\n",
    "def tensor_to_ix(t):\n",
    "    v,i = torch.max(t,1)\n",
    "    return i.data[0][0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# nn module\n",
    "class CharRNN(nn.Module):\n",
    " \n",
    "    def __init__(self, token_size, input_size, hidden_size):\n",
    "        super(CharRNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.token_size = token_size\n",
    "        \n",
    "        self.encoder = nn.Embedding(token_size, input_size)\n",
    "        self.rnn = nn.RNNCell(input_size, hidden_size , nonlinearity='relu')\n",
    "        self.linear = nn.Linear(hidden_size, token_size)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        emb = self.encoder(input).view(1,-1)\n",
    "        hidden = self.rnn(emb, hidden)\n",
    "        output = self.linear(hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return Variable(torch.FloatTensor(1, self.hidden_size).zero_())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rnn = CharRNN(token_size,input_size, hidden_size)\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(rnn.parameters(), lr=learning_rate)\n",
    "\n",
    "def train(inputs, targets, hprev):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss = 0\n",
    "    for i in range(len(inputs)):\n",
    "        input = ix_to_tensor(inputs[i])\n",
    "        target = Variable(torch.LongTensor([targets[i]]))\n",
    "\n",
    "        output, hprev = rnn(input, hprev)\n",
    "        loss += criterion(output, target)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.data[0] , hprev\n",
    "\n",
    "def sample(seed_ix, n):\n",
    "    h = rnn.init_hidden()\n",
    "\n",
    "    x = ix_to_tensor(seed_ix)\n",
    "    ixes = []\n",
    "    for t in range(n):\n",
    "        output, h = rnn(x, h)\n",
    "        ix = tensor_to_ix(output)\n",
    "        ixes.append(ix)\n",
    "        x = ix_to_tensor(ix)\n",
    "        \n",
    "    return ixes    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      " gA]gA]gA]gA]gA]gA]gA]gA]gA]gA]gA]gA]gA]gA]gA]gA]gA]gA]gA]gA]gA]gA]gA]gA]gA]gA]gA]gA]gA]gA]gA]gA]gA]gA]gA]gA]gA]gA]gA]gA]gA]gA]gA]gA]gA]gA]gA]gA]gA]gA]gA]gA]gA]gA]gA]gA]gA]gA]gA]gA]gA]gA]gA]gA]gA]gA]gA \n",
      "----\n",
      "iter 0, loss: 96.90538024902344\n",
      "----\n",
      " the ing eistion, in ond the tision inglrscan  in lrscan  in l tiscan  ind rica  on rnderstin , demeding, dean  on lrscan  in lrscan  in l tiscan  ind rica  on rnderstin , demeding, dean  on lrscan  in \n",
      "----\n",
      "iter 1000, loss: 56.057350158691406\n",
      "----\n",
      " the the the womputers in , andexstalscall ta uing of vheistinding consthcs, dith the the wornd the the the the the the the the the the the the the the the the the the the the the the the the the the t \n",
      "----\n",
      "iter 2000, loss: 30.699487686157227\n",
      "----\n",
      " y thect fomation, e.at  mede fornd thect fothe wornd the tee reac  orte the teect methction, thac, vasuan in geonran, deer tisuan .eans frd reate taskal naag toaodees andang the rxtind of conmering, i \n",
      "----\n",
      "iter 3000, loss: 13.839900970458984\n",
      "----\n",
      " y the real world an l thact can tr.ering or metee trec in theorydoeectinn, fbem the retofal dorrd that in oc geet connd thect fothe the exmanicat vo.odisc pio gemputee vision is an inmering, in ort eo \n",
      "----\n",
      "iter 4000, loss: 11.114968299865723\n",
      "----\n",
      " m the world the tee teextee tidir  of symbolic information from image data using models construate trect ffactica, of rnate taskstingacpute thastiors anol that wothe the teexte tems iongeromaly fr mng \n",
      "----\n",
      "iter 5000, loss: 5.859880447387695\n",
      "----\n",
      "  for acquiring, processing,r.ed the exman ird li wins hod menrc,ing, prat ws vise, snfl ditioa. F] modeus.i ucat, oc the worms of decisions.[4][5][6][7][5][6][7][5][6][7][5][6][7][5][6][7][5][6][7][5] \n",
      "----\n",
      "iter 6000, loss: 3.3469982147216797\n",
      "----\n",
      "  the rigiral images.othe image .ata using models constructed with the aid disclodstrat tfander.ace srom the reas imatev peostict tranting, inte tiscit orferstanding can be seen as the discit omage tas \n",
      "----\n",
      "iter 7000, loss: 4.1905293464660645\n",
      "----\n",
      " the with the theory behind artificial systems that  fand  fors ce steus c scitat formation of visual images (the input of the retiva) stforphina) into descriptions of the world that can in lronde tran \n",
      "----\n",
      "iter 8000, loss: 1.8393340110778809\n",
      "----\n",
      " m utacn vr.er conmat ofpioderdace sica  tose mine aciges (r ctim digion is cons ruh in or an inderdace with itherscanndr.icenwergcan di.[1][2][3]\n",
      "Computer vision is an interdisciplinary field that dea \n",
      "----\n",
      "iter 9000, loss: 0.23067450523376465\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-25d1ebaef74e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# forward seq_length characters through the net and fetch gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhprev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhprev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mhprev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhprev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-503e9d3bb05c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(inputs, targets, hprev)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_variables)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'backward should be called only on a scalar (i.e. 1-element tensor) or with gradient w.r.t. the variable'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_as_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execution_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/_functions/thnn/auto.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad_output)\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mupdate_grad_input_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_grad_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0mgi_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams_without_bias\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0madditional_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m             \u001b[0mupdate_grad_input_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlibrary_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mgi_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m             \u001b[0mgrad_input_tuple\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgrad_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n, p = 0, 0\n",
    "\n",
    "while True:\n",
    "    if p+seq_length+1 >= len(data) or n == 0: \n",
    "        hprev = rnn.init_hidden()\n",
    "        p = 0 # go from start of data\n",
    "        \n",
    "    inputs = [char_to_ix[ch] for ch in data[p:p+seq_length]]\n",
    "    targets = [char_to_ix[ch] for ch in data[p+1:p+seq_length+1]]\n",
    "\n",
    "    # sample from the model now and then\n",
    "    if n % 1000 == 0:\n",
    "        sample_ix = sample( inputs[0], 200)\n",
    "        txt = ''.join(ix_to_char[ix] for ix in sample_ix)\n",
    "        print ('----\\n {} \\n----'.format( txt) )\n",
    "\n",
    "    # forward seq_length characters through the net and fetch gradient\n",
    "    loss,hprev = train(inputs, targets, hprev) \n",
    "    hprev = Variable(hprev.data)\n",
    "    \n",
    " \n",
    "    if n % 1000 == 0:\n",
    "        print( 'iter {}, loss: {}'.format(n, loss)) # print progress\n",
    "\n",
    "    p += seq_length # move data pointer\n",
    "    n += 1 # iteration counter  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
